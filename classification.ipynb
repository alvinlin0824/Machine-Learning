{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Classification\"\n",
    "author: \"Alvin Lin\"\n",
    "date: now\n",
    "format: \n",
    "  html\n",
    "echo: false\n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: Import-Modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: Downlaod-Data\n",
    "mnist = fetch_openml('mnist_784', version = 1)\n",
    "mnist.keys()\n",
    "# Extract data and target\n",
    "x, y = mnist[\"data\"], mnist[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#| label: See-an-example\n",
    "some_digit_image = x.iloc[0].values.reshape(28,28)\n",
    "plt.imshow(some_digit_image, cmap = mpl.cm.binary, interpolation = \"nearest\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "# Compared to Target\n",
    "y.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: Split-data-into-train-and-test\n",
    "x_train, x_test, y_train, y_test = x[:60000], x[60000:], y[:60000], y[60000:]\n",
    "# For the sake of simplicity, two classes 5 or not 5\n",
    "y_train_5 = (y_train == '5')\n",
    "y_test_5 = (y_test == '5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: Stochastic-Gradient-Descent-SGD\n",
    "#| include: false\n",
    "# https://scikit-learn.org/stable/modules/sgd.html#:~:text=1.-,Classification,equivalent%20to%20a%20linear%20SVM.\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "# clf is short for classifier\n",
    "sgd_clf = SGDClassifier(random_state = 42)\n",
    "sgd_clf.fit(x_train, y_train_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: Performance-Measures\n",
    "# K-Fold cross-validation analysis and assessment\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# cross_val_score(sgd_clf, x_train, y_train_5, cv = 3, scoring = \"accuracy\")\n",
    "# https://www.evidentlyai.com/classification-metrics/accuracy-precision-recall#:~:text=the%20accuracy%20paradox.-,Accuracy%20paradox,the%20dataset%20is%20reasonably%20balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: Accuracy-metrics-is-only-suitable-for-balanced-data\n",
    "# Solutions: Confusion Matix\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "y_train_pred = cross_val_predict(sgd_clf, x_train, y_train_5, cv = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: Concise-matrix\n",
    "#  1. Precision = TP/TP+FP 2. Recall = TP/FN+TP\n",
    "# Precision: Given Test positive, it is actual positive\n",
    "# Recall: Given Actual positive, it is test positive\n",
    "print(\"Confusion Matrix\")\n",
    "confusion_matrix(y_true = y_train_5, y_pred = y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: Accuracy-Metrics\n",
    "# Precision\n",
    "print(\"Precision: \", precision_score(y_true = y_train_5, y_pred = y_train_pred))\n",
    "# Recall\n",
    "print(\"Recall: \", recall_score(y_true = y_train_5, y_pred = y_train_pred))\n",
    "# F1 Score\n",
    "print(\"F1 Score: \", f1_score(y_true = y_train_5, y_pred = y_train_pred))\n",
    "# Increasing precision reduces recall, and vice versa. This is called the precision/recall tradeoff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: y_scores\n",
    "y_scores = cross_val_predict(sgd_clf, x_train, y_train_5, cv = 3, method = \"decision_function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: Precision-versus-Recall\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_train_5, y_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: PR-Curve\n",
    "#| fig-cap: \"Precision Versus Recall\"\n",
    "plt.figure()\n",
    "plt.plot(recalls, precisions)\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: ROC(Receiver-operating-characteristic)\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "# Recall versus 1-specificity (True positive rate verus False positive rate)\n",
    "fpr, tpr, thresholds = roc_curve(y_train_5, y_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: ROC-Curve\n",
    "#| fig-cap: \"ROC\"\n",
    "plt.figure()\n",
    "plt.plot(fpr,tpr)\n",
    "# Add Reference Line\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.show()\n",
    "print(\"AUC: \", roc_auc_score(y_train_5, y_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: RandomForest\n",
    "#| include: false\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest_clf = RandomForestClassifier(random_state = 42)\n",
    "# cross_val_predict(forest_clf, x_train, y_train_5, cv = 3, method = \"predict_proba\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: Multiclass\n",
    "# Two strategies. One is OvA(one versus all) and the other(one versus one)\n",
    "sgd_clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: Multiclass-Example\n",
    "# sgd_clf.predict([x.iloc[0].values])\n",
    "# sgd_clf.decision_function([x.iloc[0].values])\n",
    "# np.argmax(sgd_clf.decision_function([x.iloc[0].values]))\n",
    "# Find the index of max decision score\n",
    "sgd_clf.classes_[np.argmax(sgd_clf.decision_function([x.iloc[12].values]))]\n",
    "# Compare the actual class\n",
    "y.iloc[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: Multiclass-RandomFroest\n",
    "forest_clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: Predict-Class\n",
    "# Predict Class\n",
    "forest_clf.predict([x.iloc[0].values])\n",
    "# Predict Probability\n",
    "forest_clf.predict_proba([x.iloc[0].values])\n",
    "# cross_val_predict(forest_clf, x_train, y_train, cv = 3)\n",
    "# Overall Predict\n",
    "# forest_clf.predict(x_train).shape\n",
    "# forest_clf.predict_proba(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: Error-Analysis\n",
    "# cross_val_predict: multiple rounds, predict one round\n",
    "y_train_pred = cross_val_predict(sgd_clf, x_train, y_train, cv = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| label: Confusion-Matrix\n",
    "confusion_matrix(y_train, y_train_pred)\n",
    "plt.matshow(confusion_matrix(y_train, y_train_pred), cmap = plt.cm.gray)\n",
    "plt.show"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
